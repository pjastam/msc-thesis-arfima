[["index.html", "Univariate Fractionally Integrated Time Series Modeling Preface", " Univariate Fractionally Integrated Time Series Modeling Piet Stam 2022-03-07 Preface This book is a replica of my MSc thesis on fractionally integrated time series modeling. It is written in order to facilitate (myself and) others to replicate the research results. Back in 1992/1993, the calculations were done in Fortran and Matlab, we now use R for ease of replication. The current status of this book is work-in-progress. The original version of my MSc thesis was finished August, 1993. Back then, I was a masters student in the Econometric Institute at Erasmus University Rotterdam. "],["acknowledgements.html", "Acknowledgements", " Acknowledgements I would like to express my deepest gratitude to my parents Rina and John, brother José and sister Karin. Each in their own way they encouraged me in good and bad times. Special thanks I owe to my girlfriend Ria. Since we met there was always this thesis to be finished, which made it difficult for me to concentrate on other things in life. She suffered from my moods when finishing this thesis and cared for me nonetheless. I am very grateful to dr. Marius Ooms who took the time for reading and correcting the thesis. I appreciate his flexibility in finding time even for discussion at evenings. Furthermore, I would like to thank prof. dr. Bernard van Praag who gave me the opportunity to acquire plenty of working skills as a student-assistant. Also I would like to thank Rob Flik, Marcel Warnaar and Arménio Bispo who created a great atmosphere to work in. Thanks as well to John Morssink, Wilbert Balk and Steven Kensenhuis with whom I lived together in Rotterdam. Finally I would like to thank all other persons who have cared for me and made it possible to reach this memorable point in my life. Thank you all very much! Piet "],["intro.html", "1 Introduction", " 1 Introduction Limits of ARMA models of long-run dynamics The emphasis in this thesis is on the long-run dynamics of univariate data generating processes. Stationary univariate stochastic processes are traditionally described by autoregressive moving-average (ARMA) models (see e.g. Box and Jenkins 1976; Priestley 1981; Judge et al 1982; Harvey 1981). However, these models are only applicable for describing long-run behavior if the ARMA parameter values are near the boundary of the parameter space. In this case the asymptotic distributions of estimated parameters and test statistics turn out to be inadequate as approximations to the finite sample distributions thereof. Hypothesis testing based on these asymptotic distibutions is invalid then. This is for example the case if the autoregressive polynomial function contains a so-called unit-root. Models of this type are called integer integrated ARMA models (ARIMA). Furthermore, as is indicated by Sowell (1992a), an ARMA model that is designed to describe the long-run behavior is necessarily less appropriate to describe the shorterrun behavior of a process. This can be observed in the frequency domain from the spectrum which not only has power at the low frequencies associated with the long-run behavior but also at somewhat higher frequencies. Consequently, restrictions are placed on the possibilities to describe the short-run behavior of the process with a model designed for description of long-run behavior. Ideally, no restrictions are placed at other frequencies than the specific long-run frequencies. A third drawback of using ARMA models for describing longrun dynamics is the impossibility to direct the fit of the parameters to the long-run characteristics of a series. As pointed out by Cochrane (1988), maximum likelihood (asymptotically) chooses parameter values to minimize the difference of the periodogram of the realization and the spectral density of the parametric model weighted at different frequencies. Consequently, the maximum likelihood parameter estimates may have been sacrificed to obtain a better description of the short-run dynamics although our interest centers on long-run dynamics. Fractional models When investigating the long-run behavior of a time series, a model should be considered that allows the long-run behavior to be captured. Clearly, the ARMA models are not typically suited for modeling longrun dynamics. We therefore introduce univariate fractionally integrated ARMA models (ARFIMA), which turn out to have some desirable properties for this purpose (Granger and Joyeux 1980; Hosking 1981). ARFIMA models are a generalization of ARIMA models in that the integration parameter is not restricted to take integer values only. It turns out that processes that are integrated of an order less than a half are stationary nonetheless: we can define an autocorrelation function and a pseudo spectral density in this case. The autocorrelation function decays hyperbolically to zero and thus more slowly than autocorrelation functions of stationary ARMA processes which converge to zero exponentially. In the frequency domain we observe a generalization of the spectral density behavior near zero frequency as compared to behavior typical for ARFIMA processes. The integration parameter dictates how long shocks are felt in the system, i.e. the persistence of shocks. Furthermore, the longrun dependence given a fractional order of integration is achieved with less restrictions on the higher frequency behavior of the series than with integer order of integration. A third comparative advantage of ARFIMA models is the possibility to direct the parameter estimates for purposes one wants the model to be used for. Hosking (1981) shows that in the ARFIMA model the short-run dynamics of a process are captured by the autoregressive and moving-average parameters, whereas the fractional integration parameter captures its long-run behavior. As a measure of long-run dependence we apply the cumulative impulse response measure. Given a Wold decomposition (e.g. Box and Jenkins 1976) the value of this measure is equal to the moving-average polynomial function evaluated at frequency zero, i.e. at exp{0} = 1. Cochrane (1988) states that measures based on this quantity are the only measures of the presence of a zero frequency unit root in a finite sample. ARFIMA models appear useful for other purposes than long-run dynamics description as well. Traditionally, (augmented) DickeyFuller tests are applied to a realization in order to test the null hypothesis of an autoregressive unit-root against a whole class of stationary alternatives: rejection of the null hypothesis then implies stationarity. Fitting an ARFIMA model without any autoregressive and moving-average parameters to the sample allows one to determine the fractional order of integration, i.e. any real value between zero and one is allowed (Hassler 1993). Given the DickeyFuller test of a point-hypothesis against a whole class of points, this amounts to a more symmetrical treatment of the null and alternative hypothesis. Furthermore, it should be noted that rejection of the Dickey-Fuller null hypothesis does not rule out non-stationary behavior. Only a parameter value between zero and a half implies stationarity. If the Geweke and Porter-Hudak (1983) two-stage semi-parametric estimation procedure is applied an additional advantage of this alternative unit root testing strategy is that no model structure has to be specified preceding the estimation stage. As an example of an application of the generalization described above we note that deterministic long-run behavior of processes is modeled as a polynomial of time. Linear trends are commonly observed in econometric and economic literature. Discrimination between stochastic and deterministic trend behavior amounts to specifying a model that nests both types of long-run dynamics and subsequently testing the order of integration. Allowing for fractional integration parameter values enriches the class of admissible possibilities such that mixtures of both types are allowed as well. Compare for instance Nelson and Plosser (1982) to Sowell (1992a). Outline of the study In Section 2 we describe the theory underlying ARMA, ARIMA and ARFIMA modeling of univariate stochastic processes. We highlight the unit root testing strategies and the prediction theory associated with the three model types. The consequences of deterministic trend behavior for modeling the processes are treated as well. In Section 3 we present the estimation methods. In this thesis the nonfractional ARMA parameters are estimated using three estimation methods, i.e. Yule-Walker, ordinary least-squares and maximum likelihood. The fractional parameter in the ARFIMA model is estimated using two methods. The first method is the two-stage estimation procedure as proposed by Geweke and Porter-Hudak (1983) the integration parameter is estimated first by using a frequency domain property of ARFIMA processes; the ARMA parameters of the transformed process are modeled afterwards. The other method is maximum likelihood estimation as proposed by Sowell (1992b), such that the integration parameter and ARMA parameters are estimated simultaneously. In Section 4 we illustrate the theory with economic and non-economic data sequences. The economic series is quarterly real US gross national product (seasonally adjusted, 172 data points); the non-economic series is annual Trier oak tree ring widths (1143 data points). Section 5 concludes. "],["tsmodels.html", "2 Time series models 2.1 ARMA models", " 2 Time series models In Section 2.1 we discuss the traditional socalled ARMA models. The concept of asymptotic stationarity plays a crucial role here. In Section 2.2 we present the natural extension to integrated ARMA models, where the so-called order of integration is traditionally restricted to integer values. In Section 2.3 we come to the main body of this thesis, fractionally integrated ARMA processes which allow the integration order to take any real value. These kinds of models are particularly useful to model long-term dynamics. Simulation experiments are presented in Section 2.4 in order to get a grasp of the empirical implications of the presented fractional integration theory. 2.1 ARMA models Suppose that a univariate stochastic process y with zero mean has the following AutoRegressive Moving Average model, i.e. \\(y \\sim ARMA(p+d,q)\\): \\[\\alpha (L) y_t = \\theta (L) \\epsilon _t\\] where \\[\\alpha (L) = 1 - \\alpha_1 L - \\alpha_2 L^2 - ... - \\alpha_{p+d} L^{p+d}\\] and \\[\\theta (L) = 1 - \\theta_1 L - \\theta_2 L^2 - ... - \\theta_{q} L^{q}\\] where \\(y_t\\) is a realization of the process \\(y\\) (\\(t = 1, 2, . . . , T\\)), \\(L\\) is a lag-operator such that and \\(\\epsilon_t\\) is the \\(t\\)-th observation of a covariance stationary stochastic error process. A process \\(\\epsilon\\) will be called covariance stationary if its first two moments exist, are finite, and are independent of time; covariances only depend on the time span between two observations of the process: \\[\\mathbb{E} (\\epsilon_t) = \\mu_\\epsilon\\] \\[\\mathbb{E} (\\epsilon_t - \\mu_\\epsilon)^2 = \\sigma_\\epsilon^2\\] \\[\\mathbb{E} (\\epsilon_t - \\mu_\\epsilon) (\\epsilon_{t-k} - \\mu_\\epsilon) = \\gamma_\\epsilon(k)\\] where \\(|\\mu_\\epsilon| &lt; \\infty\\), \\(\\sigma_\\epsilon^2 &lt; \\infty\\) and \\(|\\gamma_\\epsilon(k)| &lt;\\infty, k=1,2,...\\). A stationary process \\(\\epsilon\\) is said to be ergodic if the sample mean of every function of finite observations tends to its expected value in mean square, at least when the expected value of the square of the function exists (Griliches and Intriligator 1983, p. 243, footnote 7). The following quantities are consistent estimators of the mean \\(\\mu_\\epsilon\\), variance \\(\\sigma_\\epsilon^2\\) and covariances \\(\\gamma_\\epsilon(k)\\) respectively (Harvey 1981, except for the correction factors for the variance and covariances): \\[\\hat{\\mu}_\\epsilon = T^{-1} \\sum_{t=1}^{\\infty} \\epsilon_t\\] \\[\\hat{\\sigma}_\\epsilon^2 = (T-1)^{-1} \\sum_{t=1}^{\\infty} (\\epsilon_t - \\hat{\\mu}_\\epsilon)^2\\] \\[\\hat{\\gamma}_\\epsilon(k) = (T-k-1)^{-1} \\sum_{t=1}^{\\infty} (\\epsilon_t - \\hat{\\mu}_\\epsilon) (\\epsilon_{t-k} - \\hat{\\mu}_\\epsilon)\\] In this case, a single very long realization of the stationary process allows us to infer everything about the probability law generating that process, i.e. the finite sample moments converge to the infinite sample moments, which are equal to the population moments with probability one (Nerlove, Grether and Carvalho 1979). If we say that \\(\\epsilon\\) is stationary, we hereafter assume that it is ergodic as well and that it has finite moments. Furthermore, Unless stated otherwise in this thesis, \\(\\epsilon_t\\) will be assumed to be a normally distributed series of independent random shocks with zero mean and variance \\(\\sigma_\\epsilon^2\\), i.e. \\(\\epsilon_t\\) ~ N(0,\\(\\sigma_\\epsilon^2\\)). We speak of white noise. Given this covariance stationary process \\(\\epsilon\\), what can we say about the stochastic properties of the process \\(y\\)? To study these properties we have to investigate the properties of the lag-polynomials \\(\\alpha(L)\\) and \\(\\theta(L)\\). Because the algebra of these polynomial operators is isomorphic to the algebra of the polynomial functions \\(\\alpha(z)\\) and \\(\\theta(z)\\) (see Franses 1991 and the references therein), we can study the properties of the polynomial operator \\(\\alpha(L)\\) by looking at the polynomial functions \\(\\alpha(z)\\) and \\(\\theta(z)\\), \\(z\\) being a complex variable. The behavior of the discrete time series \\(y_t\\) is different as the roots of the equations \\(|\\alpha(z)| = 0\\) and \\(|\\theta(z)| = 0\\)  the zeros of the determinants of the polynomials \\(\\alpha(z)\\) and \\(\\theta(z)\\)  fall in different regions of the complex plane. 2.1.1 Helper functions figure2 &lt;- function(nobs,modelchoice,pos_corr) { par(mfrow = c(4, 2)) layout(matrix(c(1,2,3,4,5,5,6,6), 4, 2, byrow = TRUE)) #https://stackoverflow.com/questions/21893165/assigning-names-in-a-list-using-variables model1 &lt;- list(); model1[[modelchoice]] &lt;- pos_corr*0.1 model2 &lt;- list(); model2[[modelchoice]] &lt;- pos_corr*0.5 model3 &lt;- list(); model3[[modelchoice]] &lt;- pos_corr*0.9 sim1 &lt;- arima.sim(n=nobs,model1) sim2 &lt;- arima.sim(n=nobs,model2) sim3 &lt;- arima.sim(n=nobs,model3) plot(sim1,main=paste0(toupper(modelchoice),&#39;(1) (T=&#39;,nobs,&#39;, param=&#39;,pos_corr*0.1,&#39;)&#39;),xlab=&quot;time&quot;,ylab=&quot;&quot;) plot(sim2,main=paste0(toupper(modelchoice),&#39;(1) (T=&#39;,nobs,&#39;, param=&#39;,pos_corr*0.5,&#39;)&#39;),xlab=&quot;time&quot;,ylab=&quot;&quot;) plot(sim3,main=paste0(toupper(modelchoice),&#39;(1) (T=&#39;,nobs,&#39;, param=&#39;,pos_corr*0.9,&#39;)&#39;),xlab=&quot;time&quot;,ylab=&quot;&quot;) plot.new() plot(ARMAacf(eval(parse(text = paste0(modelchoice,&#39;=&#39;,0.1))), lag.max = 100),type=&quot;l&quot;,main=&#39;Theoretical autocorrelation functions&#39;,xlab=&quot;lags&quot;,ylab=&quot;&quot;,ylim=c(-1,1)); lines(ARMAacf(eval(parse(text = paste0(modelchoice,&#39;=&#39;,0.5))), lag.max = 100),type=&quot;l&quot;,lty=&quot;dashed&quot;); lines(ARMAacf(eval(parse(text = paste0(modelchoice,&#39;=&#39;,0.9))), lag.max = 100),type=&quot;l&quot;,lty=&quot;dotted&quot;); legend(&quot;topright&quot;,legend=c(expression(alpha ~ &quot;=0.9 &quot;),expression(alpha ~ &quot;=0.5 &quot;),expression(alpha ~ &quot;=0.1 &quot;)), lty=c(&quot;dotted&quot;,&quot;dashed&quot;,&quot;solid&quot;), bty = &quot;n&quot;) library(&quot;TSA&quot;) sd1 &lt;- ARMAspec(model=model1, plot = FALSE) sd2 &lt;- ARMAspec(model=model2, plot = FALSE) sd3 &lt;- ARMAspec(model=model3, plot = FALSE) detach(package:TSA) plot(sd1$freq,sd1$spec,type=&quot;l&quot;,main=&#39;Spectral densities&#39;,xlab=expression(&quot;fractions of&quot; ~ 2*pi),ylab=&quot;&quot;, ylim=c(0,10)) lines(sd2$freq,sd2$spec,type=&quot;l&quot;,lty=&quot;dashed&quot;); lines(sd3$freq,sd3$spec,type=&quot;l&quot;,lty=&quot;dotted&quot;); legend(&quot;topright&quot;,legend=c(expression(alpha ~ &quot;=0.9 &quot;),expression(alpha ~ &quot;=0.5 &quot;),expression(alpha ~ &quot;=0.1 &quot;)), lty=c(&quot;dotted&quot;,&quot;dashed&quot;,&quot;solid&quot;), bty = &quot;n&quot;) par(mfrow = c(1, 1)) } fit_arima &lt;- function(y,p,intindx,q) { npar=intindx+p+q+1 fit &lt;- arima(y, c(p, intindx, q), include.mean=TRUE) print(coef(fit)) return(fit) } fit_arfima1 &lt;- function(y,p,intindx,q) { library(&quot;arfima&quot;) fit &lt;- arfima(y, order = c(p,intindx,q), dmean=FALSE, back=TRUE) print(coef(fit)) detach(package:arfima) return(fit) } fit_arfima2 &lt;- function(y,p,q) { library(&quot;fracdiff&quot;) fit &lt;- fracdiff(y, nar = p, nma = q) print(coef(fit)) detach(package:fracdiff) return(fit) } est_stats &lt;- function(fit,loglik,npar) { print(paste(&quot;2lnL = &quot;,2*loglik)) print(paste(&quot;2lnL - 2k/T = &quot;,2*loglik-2*(npar-1))) #fit_dy$aic (npar+1) print(paste(&quot;2lnL - lnT * k/T = &quot;,2*loglik-(npar-1)*log(length(y)))) #AIC(fit_dy,k = log(length(dy))) (npar+1) } 2.1.2 Figure 2.1 figure2(300,&#39;ar&#39;,1) ## ## Attaching package: &#39;TSA&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## acf, arima ## The following object is masked from &#39;package:utils&#39;: ## ## tar 2.1.3 Figure 2.2 figure2(300,&#39;ar&#39;,-1) ## ## Attaching package: &#39;TSA&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## acf, arima ## The following object is masked from &#39;package:utils&#39;: ## ## tar 2.1.4 Figure 2.3 figure2(300,&#39;ma&#39;,1) ## ## Attaching package: &#39;TSA&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## acf, arima ## The following object is masked from &#39;package:utils&#39;: ## ## tar 2.1.5 Figure 2.4 figure2(300,&#39;ma&#39;,-1) ## ## Attaching package: &#39;TSA&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## acf, arima ## The following object is masked from &#39;package:utils&#39;: ## ## tar 2.1.6 TO DO 2.4.1 Generating a realization from some process library(fracdiff) x &lt;- fracdiff.sim( 100, ma=-.4, d=.3)$series fft computes the fast fourier transform: https://stat.ethz.ch/R-manual/R-patched/library/stats/html/fft.html spec.pgram computes the periodogram using fft: https://stat.ethz.ch/R-manual/R-patched/library/stats/html/spec.pgram.html "],["conclusions.html", "3 Conclusions", " 3 Conclusions In this thesis the emphasis was on long memory stochastic processes. Traditional ARIMA models were generalized to allow for zero frequency fractional integration instead of zero frequency integer integration only. The fractional parameter describes the long memory behavior of a stochastic process, thereby modeling low frequency behavior more flexible than when trying to model this behavior by e.g. an autoregressive filter. The autoregressive and moving-average components can be applied to describe short-term behavior. From the simulation experiments we concluded that the estimator of the population mean of fractionally integrated series can be seriously biased. In Geweke and PorterHudak (1983) the population mean has been used in the simulation study on the autocorrelation function of such series. Our experiments show that computation of this function given empirical mean leads to underestimation at all autocorrelation lags. One can partially circumvent this problem by modeling first differences. Whereas (augmented) Dickey-Fuller tests are not developed for fractionally integrated processes, zero frequency unit root tests based on estimation of the parameter of fractional integration can be used in case of fracional as well as integer integrated processes. In the second example DickeyFuller rejects the integer unit root against lower order fractional unit root. Estimation of the fractional parameter of integration is performed by the two-stage semi-parametric Geweke and Porter-Hudak (1983) procedure. Although estimation of this parameter by frequency domain log periodogram regression is independent from the mean of the series, the influence of short-run ARMA parameters can lead to serious bias in the estimator. This bias showed up when analyzing quarterly real US GNP (s.a.). Simultaneous estimation of the long and short memory parameters according to Sowell (1992a,b) performs better in this case. From the frequency domain periodograms it appeared that imposing a zero-frequency unit root by taking first differences of realizations of some process can lead to overdifferentiation. With respect to long run forecasting taking first differences is preferred over the fractional alternatives in case of quarterly real US GNP (s.a.). Overdifferentiation is present when first differences of Trier oak tree ring widths are taken. However, there is some zero frequency unit root long memory of fractional order. As the fractional alternatives are preferred, mean reversion under the fractional alternatives is present and the series is estimated as stationary although non-stationarity cannot be excluded. The oak tree data give a very clear illustration of the applicability of time series modeling in empirical work. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
